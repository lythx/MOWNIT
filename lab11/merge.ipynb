{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c210cc8",
   "metadata": {},
   "source": [
    "# Laboratorium 11 - Optymalizacja\n",
    "## Błażej Naziemiec i Szymon Żuk\n",
    "### 17 czerwca 2025\n",
    "## Wstęp\n",
    "W tym laboratorium zajmiemy się optymalizacją kosztu obliczeń funkcji. W tym celu wykonamy dwa zadania. Pierwsze z nich polega na porównaniu rozwiązania problemu predykcji typu komórek nowotworowych za pomocą metody najmniejszych kwadratów oraz regresje liniową. W drugim zadaniu musimy stworzyć algorytm, który jak najmniejszym kosztem znajdzie ścieżkę dla robota z punktu startowego do punktu końcowego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb32bf",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "Na początku zaimportowaliśmy dane odnośnie komórek nowotowrowych, które otrzymaliśmy od prowadzącego w laboratorium 2. Następnie zaimportowaliśmy funkcję `least_square`, która wykorzystując metodę najmniejszych kwadratów predykuje nam rodzaj nowotworu. Funkcja ta zwraca czteroelementową krotkę z wynikami predykcji dla macierzy: liniowej, kwadratowej, lambda oraz SVD. W tych wynikach znajdują się wartości $\\textit{true positive}$, $\\textit{true negative}$, $\\textit{false positive}$, $\\textit{false nagative}$ oraz $\\textit{accuracy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8a053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9a0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/breast-cancer.labels\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "train_data = pd.io.parsers.read_csv(\"dataset/breast-cancer-train.dat\", names=labels)\n",
    "validate_data = pd.io.parsers.read_csv(\"dataset/breast-cancer-validate.dat\", names=labels)\n",
    "train_data_malignant = train_data[train_data[\"Malignant/Benign\"] == \"M\"]\n",
    "train_data_benign = train_data[train_data[\"Malignant/Benign\"] == \"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989f3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square():\n",
    "    linear_train = train_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "    linear_validate = validate_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "\n",
    "    def create_quadratic_representation(data):\n",
    "        df = data.copy()\n",
    "        for i in range(len(quad_columns)):\n",
    "            df[f\"{i}^2\"] = data[quad_columns[i]] ** 2\n",
    "        for i in range(len(quad_columns)):\n",
    "            for j in range(i + 1, len(quad_columns)):\n",
    "                df[f\"{i}_{j}\"] = data[quad_columns[i]] * data[quad_columns[j]]\n",
    "        return df.values\n",
    "\n",
    "    quad_columns = [\"radius (mean)\", \"perimeter (mean)\", \"area (mean)\", \"symmetry (mean)\"]\n",
    "    quadratic_train = create_quadratic_representation(train_data[quad_columns])\n",
    "    quadratic_validate = create_quadratic_representation(validate_data[quad_columns])\n",
    "\n",
    "    b_training = np.where(train_data[['Malignant/Benign']] == \"M\", 1, -1)\n",
    "    b_validate = np.where(validate_data[['Malignant/Benign']] == \"M\", 1, -1)\n",
    "\n",
    "    cov_mat_lin = linear_train.T @ linear_train\n",
    "    cov_mat_quad = quadratic_train.T @ quadratic_train\n",
    "\n",
    "    weights_linear = np.linalg.solve(cov_mat_lin, linear_train.T @ b_training)\n",
    "    weights_quadratic = np.linalg.solve(cov_mat_quad, quadratic_train.T @ b_training)\n",
    "\n",
    "    λ = 0.01\n",
    "    svd = scipy.linalg.lstsq(cov_mat_lin + λ * np.eye(cov_mat_lin.shape[0]), linear_train.T @ b_training)\n",
    "\n",
    "    p_lin = linear_validate @ weights_linear\n",
    "    p_quad = quadratic_validate @ weights_quadratic\n",
    "    p_lambda = linear_validate @ weights_linear\n",
    "    p_svd = linear_validate @ svd[0]\n",
    "    def calc_acc(p_vec, b_vec):\n",
    "        tp = np.sum([1 for p, b in zip(p_vec, b_vec) if p > 0 and b > 0])\n",
    "        tn = np.sum([1 for p, b in zip(p_vec, b_vec) if p <= 0 and b < 0])\n",
    "        fp = np.sum([1 for p, b in zip(p_vec, b_vec) if p > 0 and b <= 0])\n",
    "        fn = np.sum([1 for p, b in zip(p_vec, b_vec) if p <= 0 and b > 0])\n",
    "        return int(tp), int(tn), int(fp), int(fn), float((tp + tn) / (tp + tn + fp + fn))\n",
    "\n",
    "    tp_lin, tn_lin, fp_lin, fn_lin, acc_lin = calc_acc(p_lin, b_validate)\n",
    "    tp_quad, tn_quad, fp_quad, fn_quad, acc_quad = calc_acc(p_quad, b_validate)\n",
    "    tp_lambda, tn_lambda, fp_lambda, fn_lambda, acc_lambda = calc_acc(p_lambda, b_validate)\n",
    "    tp_svd, tn_svd, fp_svd, fn_svd, acc_svd = calc_acc(p_svd, b_validate)\n",
    "    return (tp_lin, tn_lin, fp_lin, fn_lin, acc_lin), (tp_quad, tn_quad, fp_quad, fn_quad, acc_quad), (tp_lambda, tn_lambda, fp_lambda, fn_lambda, acc_lambda),(tp_svd, tn_svd, fp_svd, fn_svd, acc_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46cb6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(eps=0.0001, n_iterations=100000):\n",
    "    A = train_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "    A = np.c_[np.ones(A.shape[0]), A]\n",
    "\n",
    "    A_validate = validate_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "    A_validate = np.c_[np.ones(A_validate.shape[0]), A_validate]\n",
    "\n",
    "    b = np.where(train_data[['Malignant/Benign']] == \"M\", 1, -1)\n",
    "    b_validate = np.where(validate_data[['Malignant/Benign']] == \"M\", 1, -1)\n",
    "    \n",
    "    b = b.flatten()\n",
    "\n",
    "    AtA = A.T @ A\n",
    "\n",
    "    eigv = scipy.linalg.eigvals(AtA)\n",
    "    real_eigv = np.real(eigv)\n",
    "\n",
    "    lambda_max = np.max(real_eigv)\n",
    "    lambda_min = np.min(real_eigv)\n",
    "\n",
    "    alpha = 1 / (lambda_max + lambda_min)\n",
    "    \n",
    "    def calc_gradient(A, x, b):\n",
    "        return 2 * A.T @ (A @ x - b)\n",
    "    \n",
    "    n_samples, n_features = A.shape\n",
    "    \n",
    "    x = np.zeros(n_features)\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    while k < n_iterations:\n",
    "        x_next = x - alpha * calc_gradient(A, x, b)\n",
    "        if np.linalg.norm(x_next - x) < eps:\n",
    "            break\n",
    "        x = x_next\n",
    "        k += 1\n",
    "        \n",
    "    p = A_validate @ x\n",
    "\n",
    "    def calc_acc(p_vec, b_vec):\n",
    "        tp = np.sum([1 for p, b in zip(p_vec, b_vec) if p > 0 and b > 0])\n",
    "        tn = np.sum([1 for p, b in zip(p_vec, b_vec) if p <= 0 and b < 0])\n",
    "        fp = np.sum([1 for p, b in zip(p_vec, b_vec) if p > 0 and b <= 0])\n",
    "        fn = np.sum([1 for p, b in zip(p_vec, b_vec) if p <= 0 and b > 0])\n",
    "        total = tp + tn + fp + fn\n",
    "        accuracy = float((tp + tn) / total) if total > 0 else 0.0\n",
    "        return int(tp), int(tn), int(fp), int(fn), accuracy\n",
    "\n",
    "    tp, tn, fp, fn, accuracy = calc_acc(p, b_validate.flatten())\n",
    "\n",
    "    return (tp, tn, fp, fn, accuracy), k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10945579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki otrzymane z kodu z laboratorium 2:\n",
      "Czas wykonania: 0.0532 sekund\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((58, 194, 6, 2, 0.9692307692307692),\n",
       " (55, 185, 15, 5, 0.9230769230769231),\n",
       " (58, 194, 6, 2, 0.9692307692307692),\n",
       " (55, 199, 1, 5, 0.9769230769230769))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Wyniki otrzymane z kodu z laboratorium 2:\")\n",
    "start_time = time()\n",
    "least_square_results = least_square()\n",
    "end_time = time()\n",
    "print(f\"Czas wykonania: {end_time - start_time:.4f} sekund\")\n",
    "least_square_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dcfdfd",
   "metadata": {},
   "source": [
    "| Rodzaj metody | true positive | true negative | false positive | false negative | accuracy |\n",
    "|---------------|---------------|----------------|-----------------|-----------------|----------|\n",
    "| Liniowa       | 58           | 194            | 6             | 2             | 96.92%      |\n",
    "| Kwadratowa    | 55           | 185            | 15             | 5             | 92.31%      |\n",
    "| Lambda        | 58           | 194            | 6             | 2             | 96.92%      |\n",
    "| SVD           | 55           | 199            | 1             | 5             | 97.69%      |\n",
    "\n",
    "*Tabela 1. Wyniki predykcji typu komórek nowotworowych dla różnych macierzy metody najmniejszych kwadratów*\n",
    "\n",
    "Analizując wyniki z tabeli 1 możemy zauważyć, że najlepsze wyniki uzyskaliśmy dla macierzy SVD i jego dokładność wynosi 97.69%. Następnie wykonaliśmy operację regresji liniowej dla tych samych danych, a wyniki przedstawiliśmy w tabeli 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18800c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki otrzymane z gradientu:\n",
      "Czas wykonania: 2.6469 sekund\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((58, 177, 23, 2, 0.9038461538461539), 100000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time()\n",
    "grad_result, grad_iterations = gradient_descent()\n",
    "print(\"Wyniki otrzymane z gradientu:\")\n",
    "end_time = time()\n",
    "print(f\"Czas wykonania: {end_time - start_time:.4f} sekund\")\n",
    "grad_result, grad_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332cd0b",
   "metadata": {},
   "source": [
    "| true positive | true negative | false positive | false negative | accuracy | liczba iteracji |\n",
    "|---------------|----------------|-----------------|-----------------|----------|-----------------|\n",
    "| 58            | 177            | 23               | 2               | 90.38%   | 100000           |\n",
    "\n",
    "*Tabela 2. Wyniki regresji logistycznej dla danych komórek nowotworowych*\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02ea13",
   "metadata": {},
   "source": [
    "Z tabeli 2 wynika, że dokładność regresji logistycznej wynosi 90.38%, co jest gorszym wynikiem niż w przypadku metody najmniejszych kwadratów dla każdego typu macierzy. W związku z tym możemy stwierdzić, że metoda najmniejszych kwadratów jest lepsza w tym przypadku. Warto również zwrócić uwagę na teoretyczne złożoności czasowe obu rozwiązań. Metoda najmniejszych kwadratów ma złożoność $O(nm^2+m^3)$, gdzie złożoność regresji liniowej to $O(knm)$, gdzie $k$ to liczba iteracji. Patrząc po powyższych wynikach można zauważyć, że metoda najmniejszych kwadratów, mimo iż liczyła dla 4 różnych macierzy, to i tak wykonała się szybciej niż regresja logistyczna. Jest to spowodowane dużą liczbą iteracji, która została wykonana. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
