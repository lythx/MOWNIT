{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "b2dd1709e7507970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_vec = np.array([\n",
    "    1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980\n",
    "], dtype=np.double)\n",
    "y_vec = np.array([\n",
    "    76_212_168,\n",
    "    92_228_496,\n",
    "    106_021_537,\n",
    "    123_202_624,\n",
    "    132_164_569,\n",
    "    151_325_798,\n",
    "    179_323_175,\n",
    "    203_302_031,\n",
    "    226_542_199,\n",
    "], dtype=np.double)"
   ],
   "id": "715330fd10e95737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Zadanie 1.\n",
    "a) Najpierw wyznaczyliśmy współczynniki wielomianów dla `m=0..6` za pomocą wzoru $$A^T A c = A^T y$$ Wyznaczyliśmy macierz `A` funkcją `np.vander()`, a potem wektor `c` funkcją `np.linalg.solve()`. Następnie obliczyliśmy wartości wielomianu dla `x=1990` i wyznaczyliśmy błędy ekstrapolacji:"
   ],
   "id": "2217856dda7b382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "c_vec = []\n",
    "for m in range(7):\n",
    "    A = np.vander(x_vec, m + 1, increasing = True)\n",
    "    c = np.linalg.solve(A.T @ A, A.T @ y_vec)\n",
    "    c_vec.append(c)"
   ],
   "id": "bd7dd0bcac4f0006",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "correct_1990 = 248709873\n",
    "\n",
    "def approx(x, m):\n",
    "    return sum([c_vec[m][i] * x**i for i in range(m + 1)])\n",
    "\n",
    "extrapolated_values = [approx(1990, m) for m in range(7)]\n",
    "\n",
    "print(\"Wartości z ekstrapolacji:\\n\" + '\\n'.join([f'{int(x)}, m={m}' for m, x in enumerate(extrapolated_values)]))\n",
    "print(\"Błędy względne ekstrapolacji:\\n\" + '\\n'.join([f'{abs(float((x - correct_1990) / correct_1990)):.4f}, m={m}' for m, x in enumerate(extrapolated_values)]))"
   ],
   "id": "8a6e6b41ca27100b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Najmniejszy błąd względny otrzymaliśmy dla `m=6` równy `0.0032`. Dla wartości różnych od `m=0` błędy są małe co pokazuje skuteczność aproksymacji. \n",
    "\n",
    "b) Dla `m=0..6` wyznaczyliśmy kryterium informacyjne Akaikego ze wzoru $$\\text{AIC} = 2k + n \\ln \\left( \\frac{\\sum_{i=1}^{n} |y_i - \\hat{y}(x_i)|^2}{n} \\right)$$ Ze względu na mały rozmiar próbki wyznaczyliśmy także kryterium ze składnikiem korygującym $$\\text{AIC}_c = \\text{AIC} + \\frac{2k(k+1)}{n-k-1}$$ Otrzymaliśmy następujące wyniki:"
   ],
   "id": "f579e907df16252f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aic_c_vec = []\n",
    "n = len(x_vec)\n",
    "for m in range(7):\n",
    "    k = m + 1\n",
    "    s = sum([(y - approx(x, m))**2 for (x, y) in zip(x_vec, y_vec)])\n",
    "    aic = 2 * k + n * np.log(s / n)\n",
    "    aic_c = aic + (2 * k * (k + 1)) / (n - k - 1)\n",
    "    aic_c_vec.append(aic_c)\n",
    "\n",
    "print(\"Wartości AICc:\\n\" + '\\n'.join([f'{float(x):.2f}, m={m}' for m, x in enumerate(aic_c_vec)]))"
   ],
   "id": "4e81b0c69f5657f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Mniejsze wartości kryterium oznaczają lepszy model, zatem według kryterium najlepszym modelem jest wielomian o stopniu `m=2`. Nie zgadza się to z poprzednio wyliczonymi błędami, które były mniejsze dla `m=4` i `m=6`.\n",
    "\n",
    "Zadanie 2.\n",
    "Najpierw zdefiniowaliśmy funkcje $$ T_0 = 1, \\quad T_1 = x, \\quad T_2 = 2x^2 - 1, \\quad w = (1 - x^2)^{(-\\frac{1}{2})} $$ Następnie wyznaczyliśmy współczynniki wielomiany ze wzoru $$ c_k = \\frac{\\langle f, T_k \\rangle}{\\langle T_k, T_k \\rangle} $$ Przy całkowaniu uwzględniliśmy przesunięcie przedziału `[0, 2]` względem `[-1, 1]` $$ \\langle f, T_k \\rangle = \\int_{0}^{2} w(x - 1)f(x)T_k(x - 1) \\, dx $$ Potem wyznaczyliśmy wielomian aproksymacyjny ze wzoru $$ p_n = \\sum_{k=0}^{n} c_k \\phi_k $$"
   ],
   "id": "f030acf75233a7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "f = lambda x: np.sqrt(x)\n",
    "domain = (0, 2)\n",
    "m = 2\n",
    "T = lambda k, x: (1, x, 2 * x ** 2 - 1)[k]\n",
    "w = lambda t: (1 - t ** 2) ** (-1 / 2)\n",
    "TjTj = lambda j: np.pi if j == 0 else np.pi / 2\n",
    "\n",
    "c_vec = [integrate.quad(lambda x: w(x - 1) * f(x) * T(j, x - 1), 0, 2)[0] / TjTj(j) for j in range(m + 1)]\n",
    "p = lambda x: np.sum([c_vec[k] * T(k, x - 1) for k in range(m + 1)])\n",
    "xs = np.linspace(0, 2, 100)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(xs, f(xs), label='f(x)')\n",
    "plt.plot(xs, [p(x) for x in xs], label='Aproksymacja wielomianem 2 stopnia')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Wykres funkcji f(x) i jej aproksymacji')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "894a2b6dff716cf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Jak widać na wykresie wielomian aproksymacyjny 2 stopnia jest bardzo zbliżony do funkcji `f(x)` co pokazuje skuteczność aproksymacji.",
   "id": "62761a2a6f346d1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
