{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6af01b",
   "metadata": {},
   "source": [
    "# Laboratorium 02 - Metoda najmniejszych kwadatów\n",
    "## Błażej Naziemiec i Szymon Żuk\n",
    "### 18 marca 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aca0e1",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "Celem zadania jest zastosowanie metody najmniejszych kwadratów do predykcji, czy nowotwór jest złośliwy (ang. $\\textit{malignant}$)\n",
    "czy łagodny (ang. $\\textit{benign}$).\n",
    "Nowotwory złośliwe i łagodne mają różne charakterystyki wzrostu. Istotne cechy to m. in. promień i tekstura.\n",
    "Charakterystyki te wyznaczane są poprzez diagnostykę obrazową i biopsje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b02910",
   "metadata": {},
   "source": [
    "Na początku zaczytaliśmy dane z przygotowanych plików .dat i wrzuciliśmy je na histogram oraz wykres punktowy. W wykresie punktowym zgodnie z poleceniem posortowaliśmy wartośc kolumny od najmniejszej do największej. Wybraliśmy $\\textit{symmetry (mean)}$ do przedstawienia na historgramie oraz wykresie."
   ]
  },
  {
   "cell_type": "code",
   "id": "a376482fefa05e03",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc306e51135344ff",
   "metadata": {},
   "source": [
    "with open(\"dataset/breast-cancer.labels\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "train_data = pd.io.parsers.read_csv(\"dataset/breast-cancer-train.dat\", names=labels)\n",
    "validate_data = pd.io.parsers.read_csv(\"dataset/breast-cancer-validate.dat\", names=labels)\n",
    "train_data_malignant = train_data[train_data[\"Malignant/Benign\"] == \"M\"]\n",
    "train_data_benign = train_data[train_data[\"Malignant/Benign\"] == \"B\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5a761b32138b985",
   "metadata": {},
   "source": [
    "test_column = 10\n",
    "test_column_name = labels[test_column]\n",
    "plt.figure(dpi=300)\n",
    "plt.hist(train_data_malignant[labels[test_column]], alpha=0.8, label='Malignant', color='orange')\n",
    "plt.hist(train_data_benign[labels[test_column]], alpha=0.8, label='Benign', color='blue')\n",
    "plt.xlabel(test_column_name)\n",
    "plt.ylabel(\"Ilość\")\n",
    "plt.title(f\"Histogram dla kolumny {test_column_name}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de57f5a4",
   "metadata": {},
   "source": [
    "*Rysunek 1. Histogram dla cechy $\\textit{symmetry (mean)}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a74b3",
   "metadata": {},
   "source": [
    "Rozkład dla nowotworów złośliwych jest przesunięty w prawo, co wskazuje, że złośliwe guzy nowotworowe zazwyczaj są bardziej symetryczne niż łagodne. Największa koncentracja dla nowotowrów złośliwych jest w okolicach 0.200, a dla łagodnych w okolicach 0.180.  "
   ]
  },
  {
   "cell_type": "code",
   "id": "5a1fdf192a53a1a2",
   "metadata": {},
   "source": [
    "sorted_train_data_malignant = train_data_malignant[labels[test_column]].sort_values().reset_index(drop=True)\n",
    "sorted_train_data_benign = train_data_benign[labels[test_column]].sort_values().reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e3b9d59ac1edb96",
   "metadata": {},
   "source": [
    "test_column = 10\n",
    "test_column_name = labels[test_column]\n",
    "plt.figure(dpi=300)\n",
    "plt.plot(range(len(sorted_train_data_malignant)), sorted_train_data_malignant.values, 'o', label='Malignant', color='orange')\n",
    "plt.plot(range(len(sorted_train_data_benign)), sorted_train_data_benign.values, 'o', label='Benign', color='blue')\n",
    "plt.ylabel(test_column_name)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.title(f\"Wykres dla posortowanej kolumny {test_column_name}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "394e8ac9",
   "metadata": {},
   "source": [
    "*Rysunek 2 Wykres punktowy dla cechy $\\textit{symmetry (mean)}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96458c2f",
   "metadata": {},
   "source": [
    "Dane dla nowotworów złośliwych (pomarańczowe punkty) są generalnie wyżej na wykresie niż dane dla nowotworów łagodnych, co potwierdza wcześniejszą obserwację, że złośliwe guzy nowotorowe są bardziej symetryczne niż łagodne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9c53a",
   "metadata": {},
   "source": [
    "## Macierze dla liniowej i kwadratowej metody najmniejszych kwadratów\n",
    "\n",
    "### Przygotowanie danych\n",
    "\n",
    "Stworzyliśmy reprezentacje danych zawartych w obu zbiorach dla liniowej i kwadratowej metody najmniejszych kwadratów. W następnym kroku stworzyliśmy wektor $b$ dla zbiorów nowotworów łagodnych oraz złośliwych. Następnie znaleźliśmy wagi dla liniowej oraz kwadratowej reprezentacji najmniejszych kwadratów\n",
    "przy pomocy wcześniej stworzonych macierzy i wektora $b$ z zbioru danych treningowych. Znaleźliśmy też zbiór wag przy użyciu funkcji `np.linalg.lstsq` z $$ \\lambda  = 0.01 $$"
   ]
  },
  {
   "cell_type": "code",
   "id": "c70d5b91859ed8f6",
   "metadata": {},
   "source": [
    "linear_train = train_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "linear_validate = validate_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "\n",
    "def create_quadratic_representation(data):\n",
    "    df = data.copy()\n",
    "    for i in range(len(quad_columns)):\n",
    "        df[f\"{i}^2\"] = data[quad_columns[i]] ** 2\n",
    "    for i in range(len(quad_columns)):\n",
    "        for j in range(i + 1, len(quad_columns)):\n",
    "            df[f\"{i}_{j}\"] = data[quad_columns[i]] * data[quad_columns[j]]\n",
    "    return df.values\n",
    "\n",
    "quad_columns = [\"radius (mean)\", \"perimeter (mean)\", \"area (mean)\", \"symmetry (mean)\"]\n",
    "quadratic_train = create_quadratic_representation(train_data[quad_columns])\n",
    "quadratic_validate = create_quadratic_representation(validate_data[quad_columns])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1e75d49a1ab9541",
   "metadata": {},
   "source": [
    "b_training = np.where(train_data[['Malignant/Benign']] == \"M\", 1, -1)\n",
    "b_validate = np.where(validate_data[['Malignant/Benign']] == \"M\", 1, -1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "afeda8903bfea07f",
   "metadata": {},
   "source": [
    "cov_mat_lin = linear_train.T @ linear_train\n",
    "cov_mat_quad = quadratic_train.T @ quadratic_train"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1ee38d663db5eac",
   "metadata": {},
   "source": [
    "weights_linear = np.linalg.solve(cov_mat_lin, linear_train.T @ b_training)\n",
    "weights_quadratic = np.linalg.solve(cov_mat_quad, quadratic_train.T @ b_training)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ff2a747038568c9",
   "metadata": {},
   "source": [
    "λ = 0.01\n",
    "svd = scipy.linalg.lstsq(cov_mat_lin + λ * np.eye(cov_mat_lin.shape[0]), linear_train.T @ b_training)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73be0737",
   "metadata": {},
   "source": [
    "### Wyznaczenie współczynnika uwarunkowania macierzy dla liniowej i kwadratowej metody najmniejszych kwadratów\n",
    "\n",
    "Za pomocą funkcji $ np.linalg.cond(A^{T}A) $ wyznaczyliśmy współczynnik uwarunkowania macierzy dla liniowej i kwadratowej metody najmniejszych kwadratów. Dla poszczególnych metod otrzymaliśmy następujące wyniki:\n",
    "\n",
    "  - Dla liniowej metody najmniejszych kwadratów: $1.8092 * 10^{12}$\n",
    "  - Dla kwadratowej metody najmniejszych kwadratów: $9.0568 * 10^{17}$\n",
    "  - Dla liniowej metody z regularyzacją: $5.29336 * 10^{10}$ \n",
    "\n",
    "Wartości zarówno dla liniowej, jak i kwadratowej metody najmniejszych kwadratów są duże, co oznacza, że macierze są źle uwarunkowane. Wartości dla macierzy kwadartowej są bardzo wysokie. Najlepszy wyniki osiągneliśmy dla metody SVD, gdzie współczynnik uwarunkowania macierzy był najmniejszy. Przez to, że macierze są źle uwarunkowe, wagi nie będą dokładne. Dla liniowej metody niepewne będzie 12 ostatnich cyfr, dla kwadratowej 17, a dla liniowej z regularyzacją 10."
   ]
  },
  {
   "cell_type": "code",
   "id": "57c5294279ee65e6",
   "metadata": {},
   "source": [
    "cond_lin = np.linalg.cond(cov_mat_lin)\n",
    "cond_quad = np.linalg.cond(cov_mat_quad)\n",
    "cond_lambda = np.linalg.cond(cov_mat_lin + λ * np.eye(cov_mat_lin.shape[0]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ae231276711c6d0",
   "metadata": {},
   "source": [
    "p_lin = linear_validate @ weights_linear\n",
    "p_quad = quadratic_validate @ weights_quadratic\n",
    "p_lambda = linear_validate @ weights_linear\n",
    "p_svd = linear_validate @ svd[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2e88161",
   "metadata": {},
   "source": [
    "## Sprawdzenie, jak dobrze otrzymane wagi przewidują typ nowotworu\n",
    "\n",
    "Dla poszczególnych metod przedstawiamy wyniki klasyfikacji dla danych testowych. W tabeli przedstawiamy wartości TP, TN, FP, FN oraz dokładność klasyfikacji.\n",
    "\n",
    "  - TP - liczba przypadków prawdziwie dodatnich\n",
    "  - TN - liczba przypadków prawdziwie ujemnych\n",
    "  - FP - liczba przypadków fałszywie dodatnich \n",
    "  - FN - liczba przypadków fałszywie ujemnych\n",
    "  - Accuracy - dokładność klasyfikacji ($\\frac{TP + TN}{TP + TN + FP + FN}$)\n",
    "\n",
    "| TP | TN | FP | FN | Accuracy |\n",
    "|-------|------|-------|------|----------|\n",
    "| 58     | 194    | 6     | 2    | 96.92%      |\n",
    "\n",
    "*Tabela 1. Wyniki klasyfikacji dla liniowej metody najmniejszych kwadratów*\n",
    "\n",
    "| TP | TN | FP | FN | Accuracy |\n",
    "|-------|------|-------|------|----------|\n",
    "| 55     | 185    | 15     | 5    | 92.31%      |\n",
    "\n",
    "*Tabela 2. Wyniki klasyfikacji dla kwadratowej metody najmniejszych kwadratów*\n",
    "\n",
    "| TP | TN | FP | FN | Accuracy |\n",
    "|-------|------|-------|------|----------|\n",
    "| 55     | 199    | 1     | 5    | 97.69%      |\n",
    "\n",
    "*Tabela 3. Wyniki klasyfikacji dla macierzy do metody SVD metody najmniejszych kwadratów*\n",
    "\n",
    "| TP | TN  | FP | FN | Accuracy |\n",
    "|----|-----|----|----|----------|\n",
    "| 58 | 194 | 6  | 2  | 96.92%   |\n",
    "\n",
    "*Tabela 4. Wyniki klasyfikacji dla liniowej metody z regularyzacją*\n",
    "\n",
    "Porównując wyniki przedstawione w tabelach $(1)$, $(2)$, $(3)$ oraz $(4)$ można zauważyć, że najlepsze wyniki zwraca metoda SVD, a liniowa metoda najmniejszych kwadratów daje lepsze wyniki klasyfikacji niż kwadratowa metoda najmniejszych kwadratów. Dokładność metody z regularyzacją jest identyczna do metody bez regularyzacji.Dokładność klasyfikacji dla macierzy do metody SVD wynosi $97.69\\%$, liniowej metody z regularyzacją i bez $96.92\\%$, a dla kwadratowej $92.31\\%$. Warto jednak zauważyć, że poprawność wyników wszystkich metod jest bardzo wysoka. Świadczy to o poprawności zaimplementowanych rozwiązań.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "af89cb7f",
   "metadata": {},
   "source": [
    "def calc_acc(p_vec, b_vec):\n",
    "    tp = np.sum([1 for p, b in zip(p_vec, b_vec) if p > 0 and b > 0])\n",
    "    tn = np.sum([1 for p, b in zip(p_vec, b_vec) if p <= 0 and b < 0])\n",
    "    fp = np.sum([1 for p, b in zip(p_vec, b_vec) if p > 0 and b <= 0])\n",
    "    fn = np.sum([1 for p, b in zip(p_vec, b_vec) if p <= 0 and b > 0])\n",
    "    return int(tp), int(tn), int(fp), int(fn), float((tp + tn) / (tp + tn + fp + fn))\n",
    "\n",
    "tp_lin, tn_lin, fp_lin, fn_lin, acc_lin = calc_acc(p_lin, b_validate)\n",
    "tp_quad, tn_quad, fp_quad, fn_quad, acc_quad = calc_acc(p_quad, b_validate)\n",
    "tp_lambda, tn_lambda, fp_lambda, fn_lambda, acc_lambda = calc_acc(p_lambda, b_validate)\n",
    "tp_svd, tn_svd, fp_svd, fn_svd, acc_svd = calc_acc(p_svd, b_validate)\n",
    "tp_lambda, tn_lambda, fp_lambda, fn_lambda, acc_lambda"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89f6120b",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    " - Materiały zamieszczone na platformie Microsoft Teams w zespole $\\textit{MOwNiT 2025}$ w zakładce $\\textit{Materiały z zajęć/lab02/lab-intro02.pdf}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
